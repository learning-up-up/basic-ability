# 概率推理

贝叶斯公式：当$`{B_k}`$为一组互斥事件集时
```math
p(B_k | A) =  \frac{p(A | B_k)\,p(B_k)}{p(A)} =  \frac{p(A | B_k)\,p(B_k)}{\sum_{i = 1}^np(A|B_i)\,p(B_i)}
```
其中$`p(B_k)`$为先验概率，$`p(A|B_k)`$为似然函数，最终得到的结果为后验概率。例如当人群中患有不同病的概率$`p(B_k)`$，对于患有某种病的群体中出现症状A的概率为$`p(A|B_k)`$，人群中出现症状A的概率为$`p(A)`$，这些是方便统计的。由此我们可以得出对于医生诊断有帮助的经验。

概率推理：
```math
IF\,\,\,\,E\,\,\,\,THEN\,\,\,\,H
```
其中E为证据/前提条件，H为结论。这个式子成立就是在$`p(E)`$，求$`p(H|E)`$

# 主观贝叶斯方法

通过证据充分性度量（LS）与证据必要性度量（LN）同时考虑证据出现与证据不出现对于结论的影响。

在主管贝叶斯方法中，一个命题发生的概率可以直接由经验给出，从而方便使用。

```math
IF\,\,\,\,E\,\,\,\,THEN\,\,\,\,(LN,LS)\,\,\,\,H
```

## 几率

概率适用于重复事件，而似然性适用于非重复事件。我们引入几率（赔率）来描述事件的似然性。

在事件$`C`$的前提下，事件$`A`$相当于事件$`B`$的概率表示为
```math
odds = \frac{p(A|C)}{p(B|C)}
```
将$`B`$替换为$`\lnot A`$，得到
```math
odds = \frac{p(A|C)}{p(\lnot A|C)} = \frac{p(A|C)}{1 - p(A|C)}
```
描述了在证据出现与证据不出现两种情况下，事件A发生的相对可能性。

定义几率函数：
```math
O(X) = \frac{p(X)}{1 - p(X)}
```
几率函数与概率函数的变换是一致的，值域变为$`[0, +\infty)`$，当$`p(X) = 0.5`$时，$`O(X) = 1`$。

## 证据充分性度量与必要性度量

```math
p(H|E) = \frac{p(E|H)p(H)}{p(E)}\\
p(\lnot H|E) = \frac{p(E|\lnot H)p(\lnot H)}{p(E)}\\
```

得到
```math
\frac{p(H|E)}{p(\lnot H|E)} = \frac{p(E|H)p(H)}{p(E|\lnot H)p(\lnot H)}
```

即
```math
O(H|E) = \frac{p(E|H)}{p(E|\lnot H)} \cdot O(H) = LS \cdot O(H)
```
得到证据充分性度量$`LS = \dfrac{p(E|H)}{p(E|\lnot H)}`$。当$`LS \to \infty`$时，$`p(H|E) = 1`$，说明证据E逻辑上充分支持结论H。

类似可以得到证据必要性度量$`LN = \dfrac{p(\lnot E|H)}{p(\lnot E|\lnot H)}`$

对于充分性度量与必要性度量，两只之间的大小关系只有三种可能形式：
```math
\begin{cases}
LS > 1 > LN\\
LS = LN = 1\\
LS < 1 < LN
\end{cases}
```

## 证据不确定性表示

将证据一般可以分为
* 全证据：所有的证据$`E`$
* 部分证据：所有证据的一部分$`S`$

通常可以将$`S`$视为全证据$`E`$的可观测、观察到的部分。通过$`p(E|S)`$来描述已有证据对于全证据的支撑程度。若$`E = S`$，则$`p(E|S) = P(E)`$。

组合证据的不确定性：在观察$`S`$下，对于单一证据$`E_i`$的概率为$`p(E_i|S)`$，组合证据概率为
* $`p(E|S) = \min\{ P(E_i|S)\} \quad (E = E_1 \land E_2\land \cdots \land E_n)`$
* $`p(E|S) = \max\{ P(E_i|S)\} \quad (E = E_1 \lor E_2\lor \cdots \lor E_n)`$

## 后验概率的计算

* 证据确定存在：
```math
p(H|E) = \frac{LS\cdot p(H)}{(LS - 1)\cdotp(H) + 1}
```
* 证据确定不存在：
```math
p(H|\lnot E) = \frac{LN\cdot p(H)}{(LN - 1)\cdotp(H) + 1}
```
* 证据存在具有不确定性：只有部分观测证据$`S`$，信任程度为$`p(E|S)`$。使用杜达公式：
```math
p(H|S) = p(H|E)p(E|S) + p(H|\lnot E)p(\lnot E|S)
```
当证据$`E`$与$`S`$无关时，可化简为
```math
P(H|S) = p(H)
```

对于一般情况也可以使用相应的插值函数计算
```math
p(H|S) = 
\begin{cases}
p(H) + \dfrac{p(H|E) - p(H)}{1 - p(E)}(p(E|S) - p(E)) \quad p(E) \leqslant p(E|S)\leqslant 1\\
p(H|\lnot E) + \dfrac{p(H) - p(H|\lnot E)p(\lnot E | S)}{p(E)}p(E|S) \quad 0 \leqslant p(E|S) \leqslant p(E)
\end{cases}
```

相当于对于三种特殊情况进行分段线性插值

对于与多个独立证据支持同一结论有公式
```math
O(H|E) = \Big(\prod \dfrac{O(H|E_i)}{O(H)}\Big)\cdot O(H)
```

# 可信度

引入可信度因子$`CF(H,E)`$
```math
IF\quad E \quad THEN \quad H\quad (CF(H,E))
```
其中
```math
CF(H,E) = MB(H,E) - MD(H,E),\quad CF(H,E)\in[-1,1]
```
$`MB`$表示信任度量，$`MD`$表示不信任度量
```math
MB(H,E) = 
\begin{cases}
1, \quad p(H) = 1\\\\
\dfrac{\max\{p(H|E),p(H)\} - p(H)}{1 - p(H)}, \quad p(H)\not=1
\end{cases}\\
MD(H,E) = 
\begin{cases}
1, \quad p(H) = 0\\\\
\dfrac{\min\{p(H|E),p(H)\}- p(H)}{-p(H)}, \quad p(H)\not= 0
\end{cases}
```

若$`MB > 0`$，说明$`E`$的出现提高了$`H`$的信任度

```math
CF = 
\begin{cases}
MB = \dfrac{p(H|E) - p(H)}{1 - p(H)}, \quad p(H|E) > p(H)\\
-MD =  \dfrac{p(H|E) - p(H)}{p(H)}, \quad p(H|E) < p(H)
\end{cases}
```

## 相关性质

* 若$`MD(H|E) > 0`$

```math
MD(\lnot H|E) = MB(H|E)
```
* 可信度因子的值与E对H的支持程度呈正相关关系
* 互不相容结论对于同一因子的可信度
```math
\sum CF(H_i, E) \leq 1
```

证据的不确定性可以引入证据可信因子$`CF(E)`$来表示证据本身的不确定程度。证据可信因子可以事先给出，也可以在算法的进行中及时的更新。$`CF(E) = 1`$时确定证据为真，$`CF(E) = -1`$时确定证据为假。

组合证据的不确定性：与之前的主观贝叶斯方法类似
```math
CF(E) = 
\begin{cases}
\min\{CF(E_i)\}, \quad E = \bigwedge E_i\\
\max\{CF(E_i)\}, \quad E = \bigvee E_i
\end{cases}
```
## 基于可信度的不确定性推理
结论H的可信度公式为
```math
CF(H) = CF(H, E) \cdot \max\{CF(E), 0\}
```

***公式中没有考虑当证据为假时对于结论可信度的影响，只认为证据为假时无法判断结论的真实性，该知识不能使用。******???***

多证据不确定性的合成
```math
CF_{12}(H) = 
\begin{cases}
CF_1 + CF_2 - CF_1CF_2\quad CF_1 \geq 0,CF_2 \geq 0\\
CF_1 + CF_2 + CF_1CF_2\quad CF_1  < 0, CF_2 < 0\\
\dfrac{CF_1 + CF_2}{1 - \min\{|CF_1|, |CF_2|\}}\quad CF_1CF_2 < 0
\end{cases}
```

### 引入可信度阈值

对于CF为0时说明证据完全不支持结论（不可使用，与我们之前的定义略有出入），为1时完全支持结论。考虑$`\lambda\in(0,1]`$只有当$`CF(E) \geq \lambda`$时证据才可以使用

当没有给出阈值时就相当于默认阈值为0.
#### 不同阈值证据的不确定性合成
对于
```math
IF \quad E_1 \quad THEN \quad H \quad (CF_1(H,E_1), \lambda_1)\\
IF \quad E_2 \quad THEN \quad H \quad (CF_2(H,E_2), \lambda_2)\\
\cdots\\
IF \quad E_n \quad THEN \quad H \quad (CF_n(H,E_n), \lambda_n)\\
```
若每条知识规则都满足$`CF_i(E_i) \geq \lambda_i`$，则可以计算综合可信度为
* 极大值$`CF(H) = \max\{CF_i(H)\}`$
* 加权求和$`CF(H) = \dfrac{\sum CF(H, E_i)\cdot CF(E_i)}{\sum CF(H, E_i)}`$
* 有限和$`CF(H) = \min\{1, \sum CF_i(H)\}`$
* 递推法
```math
CF_1(H) = CF(H, E_1)\\
C_k = C_{k-1} + (1 - C_{k-1})\cdot CF(H, E_k)CF(E_k)
```

### 加权推理
引入权重因子$`w(E)`$表示证据E的重要程度，$`w(E) \in [0,1]`$。证据条件为
```math
E_1(w_i) \land E_2(w_2) \land \cdots \land E_n(w_n)
```
则组合证据的可信度为
```math
CF(E) = \dfrac{1}{\sum w_i}\sum w_i \cdot CF(E_i)
```
则结论H的可信度为
```math
CF(H) = CF(E) \cdot \max\{CF(H,E), 0\}
```

## 总结

对于每一个推理公式，首先计算出证据的可信度$`CF(E)`$，包括复杂证据与加权证据的计算。再利用公式判断证据可信度是否满足阈值，并计算$`CF_i(H) = CF(H, E_i)\max\{0, CF(E_i)\}`$。最后使用多证据可信度联立的公式两两进行合成。
```math
CF_{12}(H) = 
\begin{cases}
CF_1 + CF_2 - CF_1CF_2\\
Cf_1 + CF_2 + CF_1CF_2\\
\dfrac{CF_1 + CF_2}{1 - \min\{|CF_1|, |CF_2|\}}
\end{cases}

```

优点是使用简便，但是传播中会导致累计误差，并且组合逻辑的顺序不同会导致结果的不同

# 证据理论

解决了不确定不知道的差异，通过信任函数进行度量

## 识别框架

将所有的预测可能结果表示为一个集合，其中的每一个元素都有经验或推测来决定。记$`\Omega`$为变量$`x`$的有限个所有可能取值的非空集合，要求**各个元素互不相容**，即表示为
```math
\Omega = \set{x_1, x_2, \cdots, x_N}
```
对于一个问题所有的可能结果或者证据都可以用一个这样的识别框架来表示。**每一个命题都可以用集合的一个子集来表示**

识别框架的幂集
```math
2^{\Omega} = \set{空集, \set{x_1}, \cdots, \Omega}
```
对于一个问题，任意的结果都被包含在识别框架的幂集中

## 基本概率分配函数

对于$`2^{\Omega}`$的任意一个子集都对应一个数
```math
m(A) \in [0, 1]\\
满足m(\empty) = 0, \quad \sum_{A \subset \Omega}m(A) = 1
```
若$`m(A) > 0`$则称A为焦点元素

### 命题的信任函数

```math
Bel(A) = \sum_{B\subset A}m(B), \quad \forall A \in \Omega
```
表示对于A的总信任度，是对于A为真的信任程度，称之为A的下限函数

### 似然函数

```math
Pl(A) = 1 - Bel(\lnot A) = \sum_{B \cap A \not= \varnothing}m(B)
```
表示了对于A非假的信任程度，称为A的上限函数。

似然函数与信任函数表示了对于A信任程度的上限和下限
```math
0 \leq Bel(A) \leq Pl(A) \leq 1
```
$`\mu(A) = Pl(A) - Bel(A)`$就表示了既不信任$`A`$又不信任$`\lnot A`$的程度，刻画了不知道不确定性的程度

在推理中，有一些可以明确认为正确的结论构成的信任度就算作是下限，而除去明确不对的结论构成的信任程度则构成了上限，这其中的差距就在于未知的不确定性。

在证据理论中，$`[0,Bel(A)]`$就表示完全信任区间，$`[0,Pl(A)]`$就表示不怀疑区间。

## 德普斯特证据组合

对于不同的证据，对于同一个识别框架会有不同的概率分配函数组合，使用正交和来将不同组证据组合在一起

```math
m(A) = (m_1 \oplus m_2 \oplus \cdots \oplus m_P)(A) = \frac{1}{K}\sum_{\cap A_i = A}\prod_{1 \leq i \leq n , 1 \leq p \leq P } m_p(A_i)
```
其中$`K = 1 - \sum_{\cap A_i = \varnothing }\prod m_p(A_i)`$为归一化系数，当$`K = 0`$

特别的，当是两组证据组合时
```math
m(A) = \frac{1}{K}\sum_{A_i \cap B_j = A, a \leq i,j, \leq n}m_1(A_i)m_2(B_j)
```

## 推理

* 建立样本空间
* 计算概率分配函数
* 组合分配函数
* 计算信任函数与似然函数
* 得出结论

