# 概率推理

贝叶斯公式：当$`{B_k}`$为一组互斥事件集时
```math
p(B_k | A) =  \frac{p(A | B_k)\,p(B_k)}{p(A)} =  \frac{p(A | B_k)\,p(B_k)}{\sum_{i = 1}^np(A|B_i)\,p(B_i)}
```
其中$`p(B_k)`$为先验概率，$`p(A|B_k)`$为似然函数，最终得到的结果为后验概率。例如当人群中患有不同病的概率$`p(B_k)`$，对于患有某种病的群体中出现症状A的概率为$`p(A|B_k)`$，人群中出现症状A的概率为$`p(A)`$，这些是方便统计的。由此我们可以得出对于医生诊断有帮助的经验。

概率推理：
```math
IF\,\,\,\,E\,\,\,\,THEN\,\,\,\,H
```
其中E为证据/前提条件，H为结论。这个式子成立就是在$`p(E)`$，求$`p(H|E)`$

# 主观贝叶斯方法

通过证据充分性度量（LS）与证据必要性度量（LN）同时考虑证据出现与证据不出现对于结论的影响。

在主管贝叶斯方法中，一个命题发生的概率可以直接由经验给出，从而方便使用。

```math
IF\,\,\,\,E\,\,\,\,THEN\,\,\,\,(LN,LS)\,\,\,\,H
```

## 几率

概率适用于重复事件，而似然性适用于非重复事件。我们引入几率（赔率）来描述事件的似然性。

在事件$`C`$的前提下，事件$`A`$相当于事件$`B`$的概率表示为
```math
odds = \frac{p(A|C)}{p(B|C)}
```
将$`B`$替换为$`\lnot A`$，得到
```math
odds = \frac{p(A|C)}{p(\lnot A|C)} = \frac{p(A|C)}{1 - p(A|C)}
```
描述了在证据出现与证据不出现两种情况下，事件A发生的相对可能性。

定义几率函数：
```math
O(X) = \frac{p(X)}{1 - p(X)}
```
几率函数与概率函数的变换是一致的，值域变为$`[0, +\infty)`$，当$`p(X) = 0.5`$时，$`O(X) = 1`$。

## 证据充分性度量与必要性度量

```math
p(H|E) = \frac{p(E|H)p(H)}{p(E)}\\
p(\lnot H|E) = \frac{p(E|\lnot H)p(\lnot H)}{p(E)}\\
```

得到
```math
\frac{p(H|E)}{p(\lnot H|E)} = \frac{p(E|H)p(H)}{p(E|\lnot H)p(\lnot H)}
```

即
```math
O(H|E) = \frac{p(E|H)}{p(E|\lnot H)} \cdot O(H) = LS \cdot O(H)
```
得到证据充分性度量$`LS = \dfrac{p(E|H)}{p(E|\lnot H)}`$。当$`LS \to \infty`$时，$`p(H|E) = 1`$，说明证据E逻辑上充分支持结论H。

类似可以得到证据必要性度量$`LN = \dfrac{p(\lnot E|H)}{p(\lnot E|\lnot H)}`$

对于充分性度量与必要性度量，两只之间的大小关系只有三种可能形式：
```math
\begin{cases}
LS > 1 > LN\\
LS = LN = 1\\
LS < 1 < LN
\end{cases}
```

## 证据不确定性表示

将证据一般可以分为
* 全证据：所有的证据$`E`$
* 部分证据：所有证据的一部分$`S`$

通常可以将$`S`$视为全证据$`E`$的可观测、观察到的部分。通过$`p(E|S)`$来描述已有证据对于全证据的支撑程度。若$`E = S`$，则$`p(E|S) = P(E)`$。

组合证据的不确定性：在观察$`S`$下，对于单一证据$`E_i`$的概率为$`p(E_i|S)`$，组合证据概率为
* $`p(E|S) = \min\{ P(E_i|S)\} \quad (E = E_1 \land E_2\land \cdots \land E_n)`$
* $`p(E|S) = \max\{ P(E_i|S)\} \quad (E = E_1 \lor E_2\lor \cdots \lor E_n)`$

## 后验概率的计算

* 证据确定存在：
```math
p(H|E) = \frac{LS\cdot p(H)}{(LS - 1)\cdotp(H) + 1}
```
* 证据确定不存在：
```math
p(H|\lnot E) = \frac{LN\cdot p(H)}{(LN - 1)\cdotp(H) + 1}
```
* 证据存在具有不确定性：只有部分观测证据$`S`$，信任程度为$`p(E|S)`$。使用杜达公式：
```math
p(H|S) = p(H|E)p(E|S) + p(H|\lnot E)p(\lnot E|S)
```
当证据$`E`$与$`S`$无关时，可化简为
```math
P(H|S) = p(H)
```

对于一般情况也可以使用相应的插值函数计算
```math
p(H|S) = 
\begin{cases}
p(H) + \dfrac{p(H|E) - p(H)}{1 - p(E)}(p(E|S) - p(E)) \quad p(E) \leqslant p(E|S)\leqslant 1\\
p(H|\lnot E) + \dfrac{p(H) - p(H|\lnot E)p(\lnot E | S)}{p(E)}p(E|S) \quad 0 \leqslant p(E|S) \leqslant p(E)
\end{cases}
```

相当于对于三种特殊情况进行分段线性插值

对于与多个独立证据支持同一结论有公式
```math
O(H|E) = \Big(\prod \dfrac{O(H|E_i)}{O(H)}\Big)\cdot O(H)
```

# 可信度

引入可信度因子$`CF(H,E)`$
```math
IF\quad E \quad THEN \quad H\quad (CF(H,E))
```
其中
```math
CF(H,E) = MB(H,E) - MD(H,E),\quad CF(H,E)\in[-1,1]
```
$`MB`$表示信任度量，$`MD`$表示不信任度量
```math
MB(H,E) = 
\begin{cases}
1, \quad p(H) = 1\\\\
\dfrac{\max\{p(H|E),p(H)\} - p(H)}{1 - p(H)}, \quad p(H)\not=1
\end{cases}\\
MD(H,E) = 
\begin{cases}
1, \quad p(H) = 0\\\\
\dfrac{\min\{p(H|E),p(H)\}- p(H)}{-p(H)}, \quad p(H)\not= 0
\end{cases}
```

若$`MB > 0`$，说明$`E`$的出现提高了$`H`$的信任度

```math
CF = 
\begin{cases}
MB = \dfrac{p(H|E) - p(H)}{1 - p(H)}, \quad p(H|E) > p(H)\\
-MD =  \dfrac{p(H|E) - p(H)}{p(H)}, \quad p(H|E) < p(H)
\end{cases}
```

## 相关性质

* 若$`MD(H|E) > 0`$

```math
MD(\lnot H|E) = MB(H|E)
```
* 可信度因子的值与E对H的支持程度呈正相关关系
* 互不相容结论对于同一因子的可信度
```math
\sum CF(H_i, E) \leq 1
```

证据的不确定性可以引入证据可信因子$`CF(E)`$来表示证据本身的不确定程度。证据可信因子可以事先给出，也可以在算法的进行中及时的更新。$`CF(E) = 1`$时确定证据为真，$`CF(E) = -1`$时确定证据为假。

组合证据的不确定性：与之前的主观贝叶斯方法类似
```math
CF(E) = 
\begin{cases}
\min\{CF(E_i)\}, \quad E = \bigwedge E_i\\
\max\{CF(E_i)\}, \quad E = \bigvee E_i
\end{cases}
```
## 基于可信度的不确定性推理
结论H的可信度公式为
```math
CF(H) = CF(E) \cdot \max\{CF(H, E), 0\}
```

***公式中没有考虑当证据为假时对于结论可信度的影响，只认为证据为假时无法判断结论的真实性，该知识不能使用。******???***

多证据不确定性的合成
```math
CF_{12}(H) = 
\begin{cases}
CF_1 + CF_2 - CF_1CF_2\quad CF_1 \geq 0,CF_2 \geq 0\\
CF_1 + CF_2 + CF_1CF_2\quad CF_1  < 0, CF_2 < 0\\
\dfrac{CF_1 + CF_2}{1 - \min\{|CF_1|, |CF_2|\}}\quad CF_1CF_2 < 0
\end{cases}
```

### 引入可信度阈值

对于CF为0时说明证据完全不支持结论（不可使用，与我们之前的定义略有出入），为1时完全支持结论。考虑$`\lambda\in(0,1]`$只有当$`CF(E) \geq \lambda`$时证据才可以使用

#### 不同阈值证据的不确定性合成
对于
```math
IF \quad E_1 \quad THEN \quad H \quad (CF_1(H,E_1), \lambda_1)\\
IF \quad E_2 \quad THEN \quad H \quad (CF_2(H,E_2), \lambda_2)\\
\cdots\\
IF \quad E_n \quad THEN \quad H \quad (CF_n(H,E_n), \lambda_n)\\
```
若每条知识规则都满足$`CF_i(E_i) \geq \lambda_i`$，则可以计算综合可信度为
* 极大值$`CF(H) = \max\{CF_i(H)\}`$
* 加权求和$`CF(H) = \dfrac{\sum CF(H, E_i)\cdot CF(E_i)}{\sum CF(H, E_i)}`$
* 有限和$`CF(H) = \min\{1, \sum CF_i(H)\}`$
* 递推法
```math
CF_1(H) = CF(H, E_1)\\
C_k = C_{k-1} + (1 - C_{k-1})\cdot CF(H, E_k)CF(E_k)
```

### 加权推理
引入权重因子$`w(E)`$表示证据E的重要程度，$`w(E) \in [0,1]`$。证据条件为
```math
E_1(w_i) \land E_2(w_2) \land \cdots \land E_n(w_n)
```
则组合证据的可信度为
```math
CF(E) = \dfrac{1}{\sum w_i}\sum w_i \cdot CF(E_i)
```
则结论H的可信度为
```math
CF(H) = CF(E) \cdot \max\{CF(H,E), 0\}
```
